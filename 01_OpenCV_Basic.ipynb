{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing the open CV package\n",
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # importing the openCV library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.5.2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.__version__  # Checking which version is installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Geek4GeekS Article :\n",
    "\n",
    "<a href='https://www.geeksforgeeks.org/introduction-to-opencv/'> LINK FOR NEXR LESSON</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height = 1603 and Width = 2400\n"
     ]
    }
   ],
   "source": [
    "# Reading the image using imread\n",
    "image = cv2.imread(\"road.jpg\")\n",
    "\n",
    "# Extracting height and width of the image.\n",
    "h,w = image.shape[:2]\n",
    "\n",
    "# Displaying the height and width\n",
    "print('height = {} and Width = {}'.format(h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R =211 ,G =172, B=165\n",
      "B = 165\n"
     ]
    }
   ],
   "source": [
    "# Extracting RGB Value\n",
    "# Here we have randomly chosen a pixel\n",
    "# by passing in 100, 100 for height and width.\n",
    "(B, G, R) = image[100, 100]\n",
    "\n",
    "# Displaying the RGB Value \n",
    "print(\"R ={} ,G ={}, B={}\".format(R,G,B))\n",
    "\n",
    "# We can also pass the channel to extract \n",
    "# the value for a specific channel\n",
    "B = image[100, 100, 0]\n",
    "print(\"B = {}\".format(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the Region of Interest (ROI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will calculate the region of interest \n",
    "# by slicing the pixels of the image\n",
    "roi = image[100 : 500, 200 : 700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize() function takes 2 parameters, \n",
    "# the image and the dimensions\n",
    "resize = cv2.resize(image,(800,800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the ratio\n",
    "ratio = 800 / w\n",
    "  \n",
    "# Creating a tuple containing width and height\n",
    "dim = (800, int(h * ratio))\n",
    "  \n",
    "# Resizing the image\n",
    "resize_aspect = cv2.resize(image, dim)  # dim - Width ,Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the center of the image\n",
    "center = (w // 2, h // 2)\n",
    "  \n",
    "# Generating a rotation matrix\n",
    "matrix = cv2.getRotationMatrix2D(center, -45, 1.0) \n",
    "  \n",
    "# Performing the affine transformation\n",
    "rotated = cv2.warpAffine(image, matrix, (w, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are copying the original image, \n",
    "# as it is an in-place operation.\n",
    "output = image.copy()\n",
    "  \n",
    "# Using the rectangle() function to create a rectangle.\n",
    "rectangle = cv2.rectangle(output, (1500, 900), \n",
    "                          (600, 400), (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copying the original image\n",
    "output = image.copy()\n",
    "  \n",
    "# Adding the text using putText() function\n",
    "text = cv2.putText(output, 'OpenCV Demo', (500, 550), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 4, (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the image and showing in display\n",
    "geek_image = cv2.imread(\"geeks4.png\",cv2.IMREAD_COLOR)\n",
    "\n",
    "# Creating GUI window to display an image on screen\n",
    "# first Parameter is windows title (should be in string format)\n",
    "# Second Parameter is image array\n",
    "cv2.imshow(\"Cute Kitens\",resize_aspect)\n",
    "\n",
    "# To hold the window on screen, we use cv2.waitKey method\n",
    "# Once it detected the close input, it will release the control\n",
    "# To the next line\n",
    "# First Parameter is for holding screen for specified milliseconds\n",
    "# It should be positive integer. If 0 pass an parameter, then it will\n",
    "# hold the screen until user close it.\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# It is for removing/deleting created GUI window from screen\n",
    "# and memory\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/reading-image-opencv-using-python/   \n",
    "\n",
    "# Continuing tommorow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edureka Class\n",
    "\n",
    "## CHAPTER 1\n",
    "\n",
    "-  How to read ,write and display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing library\n",
    "# open vision lib\n",
    "import cv2\n",
    "# numpy for multidimention operation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the image\n",
    "image = cv2.imread(\"dog.jpg\")\n",
    "\n",
    "#displaying the image\n",
    "cv2.imshow(\"Dogy\",image)\n",
    "\n",
    "# until we close image will be displayed\n",
    "cv2.waitKey(0)   \n",
    "\n",
    "# closing the all window \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 500, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W ,H ,Channel\n",
    "image.shape\n",
    "\n",
    "# if B&W channel will be 1 and if color BGR it will show as 3 channel\n",
    "# Value of each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to create new image file we will use below code\n",
    "cv2.imwrite(\"copy_dog.jpg\",image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read,write and display the video \n",
    "\n",
    "### Activity 1 : Start our own video camera and record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)  # recording \n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('X','V','I','D') \n",
    "\n",
    "out = cv2.VideoWriter('output.avi',fourcc,20.0,(640,480)) # writing in the file\n",
    "\n",
    "while True:\n",
    "    success,frame = cap.read()\n",
    "    \n",
    "    if success == True:\n",
    "        out.write(frame) # this code writing frame into the file XVID\n",
    "        cv2.imshow(\"Video\",frame) #this code showing the all frame\n",
    "        \n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 2 : Reading and display the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cap.set(3, 640)#Width\n",
    "cap.set(4, 480)#Height\n",
    "cap.set(10, 100)#brightness\n",
    "\n",
    "#Videos are just a sequence of Images\n",
    "#So, we will add a while loop to go through each frame\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read() #img variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
    "    cv2.imshow(\"Video\", img)\n",
    "      \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
    "        break\n",
    "        \n",
    "cap.release() #Release the resources after recording\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grey image\n",
    "img = cv2.imread('dog.jpg')\n",
    "img_gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY) # converting color to b&W image\n",
    "cv2.imshow(\"Grey_Dogy\",img_gray)\n",
    "cv2.imwrite(\"Dogy_grey.png\",img_gray) # Saving the black & white image\n",
    "\n",
    "cv2.waitKey(0)  # until we close image will be displayed \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blur image\n",
    "\n",
    "img = cv2.imread('dog.jpg')\n",
    "blur_img = cv2.GaussianBlur(img,(21,21),0) # taking 3 argument source of image , size blur \n",
    "\n",
    "cv2.imshow(\"Grey_Dogy\",blur_img)  # title and image source \n",
    "cv2.waitKey(0)  # until we close image will be displayed \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize\n",
    "resize_img = cv2.resize(img,(200,400))\n",
    "cv2.imshow(\"Orginal Image\",img)\n",
    "cv2.imshow(\"Resized Image\",resize_img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edge Detector\n",
    "img = cv2.imread(\"dog.jpg\")\n",
    "\n",
    "#image canny\n",
    "imgcanny = cv2.Canny(img,150,200)\n",
    "\n",
    "#kernel\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "#user to connect improper line\n",
    "imgdilute = cv2.dilate(imgcanny,kernel,iterations=1)\n",
    "# create thinline\n",
    "imgextrude = cv2.erode(imgdilute,kernel,iterations=1)\n",
    "\n",
    "# itertion - how much thickness actually we need.\n",
    "cv2.imshow(\"Canny\",imgcanny)\n",
    "cv2.imshow(\"Canny_dilute\",imgdilute)\n",
    "cv2.imshow(\"Canny_erode\",imgdilute)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (333, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "# croping the image\n",
    "cv2.imshow(\"Image\",img)\n",
    "crop_image = img[0:200,200:400]  # height,width\n",
    "cv2.imshow(\"Croped Image\",crop_image)\n",
    "print(\"Shape\",img.shape)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 3\n",
    "\n",
    "\n",
    "#### Shapes and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 means black\n",
    "img = np.zeros((400,400))\n",
    "\n",
    "cv2.imshow(\"O\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw simple \n",
    "img = np.zeros((512,512,3),np.uint8)\n",
    "\n",
    "cv2.line(img,(0,0),(200,400),(0,255,255),10)\n",
    "\n",
    "cv2.imshow(\"O\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating rectangle\n",
    "img = np.zeros((512,512,3),np.uint8)\n",
    "\n",
    "cv2.line(img,(0,0),(200,400),(45,225,0),10)\n",
    "cv2.rectangle(img,(0,0),(200,400),(0,255,255))\n",
    "\n",
    "cv2.imshow(\"O\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circle and TEXT\n",
    "dog = cv2.imread(\"dog.jpg\")\n",
    "cv2.imshow(\"Dog\",dog)\n",
    "img = np.zeros((512,512,3),np.uint8)\n",
    "cv2.circle(img,(400,200),30,(45,235,0))\n",
    "\n",
    "cv2.putText(img,\"OPEN CV\",(100,200),cv2.FONT_HERSHEY_COMPLEX,1, (0, 150,0), 1)\n",
    "\n",
    "cv2.imshow(\"O\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining two image\n",
    "\n",
    "img = cv2.imread('dog.jpg')\n",
    "\n",
    "imghor = np.hstack((img,img))\n",
    "\n",
    "cv2.imshow(\"Horizontal Image\",imghor)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical image\n",
    "\n",
    "img = cv2.imread('dog.jpg')\n",
    "\n",
    "imghor = np.vstack((img,img))\n",
    "\n",
    "cv2.imshow(\"Horizontal Image\",imghor)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - Mini Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face detection in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\") # using pre-trained model\n",
    "\n",
    "# reading image and resize and color change to grey.\n",
    "img = cv2.imread(\"people.jpg\")\n",
    "img = cv2.resize(img,(600,400))\n",
    "img_grey = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# This code will detect the face and generate coordinated \n",
    "faces = faceCascade.detectMultiScale(img_grey,1.1,5)\n",
    "\n",
    "# draw rectangulat box around the face\n",
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "    \n",
    "cv2.imshow(\"output\",img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face detection using video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"walk.mp4\")\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\") # using pre-trained model\n",
    "\n",
    "while True:\n",
    "    success,frame = cap.read() #frame variable will be capture \n",
    "    \n",
    "    imggrey = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = faceCascade.detectMultiScale(imggrey,1.1,4)\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.imshow(\"output\",frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
    "        break\n",
    "        \n",
    "cap.release() #Release the resources after recording\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pedestrain detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('PED.mp4') # reading the video\n",
    "#Videos are just a sequence of Images\n",
    "#So, we will add a while loop to capture the frame continuously\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_fullbody.xml\")\n",
    "\n",
    "while True:\n",
    "    success,frame = cap.read() # It will read each frame of the video\n",
    "    \n",
    "    imgrey = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = faceCascade.detectMultiScale(imgrey, 1.1, 4)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),4)\n",
    "        \n",
    "    cv2.imshow(\"Video\",frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity 1 :\n",
    "\n",
    "#### Face detection in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #library\n",
    "\n",
    "cap = cv2.VideoCapture(0) # capturing the video\n",
    "\n",
    "facecast = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\") #face detection algrithm\n",
    "\n",
    "while True:\n",
    "    success,frame = cap.read() # reading each frame\n",
    "    greyIMG = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = facecast.detectMultiScale(greyIMG, 1.1, 4)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(22,245,133),2)\n",
    "        \n",
    "    cv2.imshow(\"Camera\",frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
    "        break\n",
    "            \n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Face and eye detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #library\n",
    "#Face and Eyes Detection in Real-Time\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Videos are just a sequence of Images\n",
    "#So, we will add a while loop to capture the frame continuously\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "faceCascade1 = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read() #frame variable will capture the Video & success variable will tell us whether it was captured successfully or not\n",
    "            \n",
    "        \n",
    "    imgGray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    eyes = faceCascade.detectMultiScale(imgGray, 1.1, 4)\n",
    "    faces = faceCascade1.detectMultiScale(imgGray, 1.1, 4)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x,y),(x+w,y+h),(0,0,0),2)\n",
    "    \n",
    "    for (x, y, w, h) in eyes:\n",
    "        cv2.rectangle(frame, (x,y),(x+w,y+h),(22,245,133),3)\n",
    "    \n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) == ord('q'): #This adds a Delay and looks for the key press inorder to break the loop\n",
    "        break\n",
    "            \n",
    "        \n",
    "cap.release() #Release the resources after recording\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
